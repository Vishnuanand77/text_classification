{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: huggingface-cli: command not found\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Llama2 7b tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f02cf344ea24314a3e5682117fb8da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Define the model name and cache directory\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"  # LLaMA 2-7B model\n",
    "cache_dir = \"/scratch/gilbreth/anand173/model_cache\"\n",
    "\n",
    "# Configure 4-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Use 4-bit quantization\n",
    "    bnb_4bit_use_double_quant=True,  # Enable double quantization for memory savings\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Use bfloat16 for computation\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# Load the model with 4-bit quantization and device map\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # Automatically allocate model layers across GPU/CPU\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "# Ensure the pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification response...\n",
      "Predicted Label: ### Instruction:\n",
      "Classify the following review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
      "\n",
      "### Input:\n",
      "Item was delivered on time and was a direct replcement\n",
      "\n",
      "### Response:\n",
      "Correct Size/Just Right\n",
      "\n",
      "##\n",
      "Runtime: 0.87 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Example review to classify\n",
    "review = \"Item was delivered on time and was a direct replcement\"\n",
    "\n",
    "# Format prompt for classification\n",
    "prompt = f\"\"\"### Instruction:\n",
    "Classify the following review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
    "\n",
    "### Input:\n",
    "{review}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    ").to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "# Generate the output\n",
    "print(\"Generating classification response...\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=10,           # Limit the response length\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode and display the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "print(f\"Predicted Label: {response}\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print runtime\n",
    "runtime = end_time - start_time\n",
    "print(f\"Runtime: {runtime:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification response...\n",
      "Predicted Label: ### Instruction:\n",
      "Classify the following autoparts review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
      "\n",
      "\n",
      "### Examples:\n",
      "1. Review: \"order came quickly and is working fine and is much better price than going to Lowe's or Home Depot to purchase.\"\n",
      "   Classification -> No Comment\n",
      "2. Review: \"Perfect Fit - Ideal for when you don't need to replace an otherwise good OEM axle. Fits all FWD/AWD Volvo 850   S/V70 '93-'00\"\n",
      "   Classification -> Correct Size/Just Right\n",
      "3. Review: \"two different ends on cables. doesn't make sense. had to change the end on one side to fit it to the battery.\"\n",
      "   Classification -> Wrong Size\n",
      "\n",
      "\n",
      "### Input:\n",
      "Review: \"Have not had to use it yet - but I know how handy it is to have it available. Thanks\"\n",
      "### Response:\n",
      "Correct Size/Just Right\n",
      "\n",
      "\n",
      "##\n",
      "Runtime: 0.76 seconds\n"
     ]
    }
   ],
   "source": [
    "# Few-shot examples for the classification task\n",
    "few_shot_examples = \"\"\"\n",
    "### Examples:\n",
    "1. Review: \"order came quickly and is working fine and is much better price than going to Lowe's or Home Depot to purchase.\"\n",
    "   Classification -> No Comment\n",
    "2. Review: \"Perfect Fit - Ideal for when you don't need to replace an otherwise good OEM axle. Fits all FWD/AWD Volvo 850   S/V70 '93-'00\"\n",
    "   Classification -> Correct Size/Just Right\n",
    "3. Review: \"two different ends on cables. doesn't make sense. had to change the end on one side to fit it to the battery.\"\n",
    "   Classification -> Wrong Size\n",
    "\"\"\"\n",
    "\n",
    "# Example review to classify\n",
    "review = \"Have not had to use it yet - but I know how handy it is to have it available. Thanks\"\n",
    "\n",
    "# Format prompt with few-shot examples\n",
    "prompt = f\"\"\"### Instruction:\n",
    "Classify the following autoparts review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "### Input:\n",
    "Review: \"{review}\"\n",
    "### Response:\n",
    "\"\"\"\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    ").to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "# Generate the output\n",
    "print(\"Generating classification response...\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=10,           # Limit the response length\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode and display the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "print(f\"Predicted Label: {response}\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print runtime\n",
    "runtime = end_time - start_time\n",
    "print(f\"Runtime: {runtime:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 10 reviews prompt version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 10 reviews saved to fit_predictions_first_10.csv.\n",
      "Runtime: 8.13 seconds\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_10.csv\"\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 10:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"### Instruction:\n",
    "Classify the following review into one of the categories: \"Correct Size/Just Right\", \"Wrong Size\", or \"No Comment\". Please respond only with the category name.\n",
    "\n",
    "### Categories:\n",
    "- \"Correct Size/Just Right\": The product fits as expected and performs its intended function without issues.\n",
    "- \"Wrong Size\": The product does not fit or requires modifications to work correctly.\n",
    "- \"No Comment\": The review does not mention size or fitting issues.\n",
    "\n",
    "### Examples:\n",
    "1. Review: \"order came quickly and is working fine and is much better price than going to Lowe's or Home Depot to purchase.\"\n",
    "   Classification -> No Comment\n",
    "2. Review: \"Perfect Fit - Ideal for when you don't need to replace an otherwise good OEM axle. Fits all FWD/AWD Volvo 850   S/V70 '93-'00\"\n",
    "   Classification -> Correct Size/Just Right\n",
    "3. Review: \"two different ends on cables. doesn't make sense. had to change the end on one side to fit it to the battery.\"\n",
    "   Classification -> Wrong Size\n",
    "\n",
    "### Input:\n",
    "Review: \"{review}\"\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 10 reviews saved to {output_file}.\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print runtime\n",
    "runtime = end_time - start_time\n",
    "print(f\"Runtime: {runtime:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted vs. Actual:\n",
      "                                          ReviewText                FINAL Fit  \\\n",
      "0  You will have to remove the window which is ve...               No Comment   \n",
      "1   It does what it is supposed to! Sure it does ...               No Comment   \n",
      "2  Item was delivered on time and was a direct re...               No Comment   \n",
      "3   This was a really great part, shipped fast, a...               No Comment   \n",
      "4  This puller worked getting off a stubborn wipe...               No Comment   \n",
      "5   Works ok, really just a quick adapter as the ...               No Comment   \n",
      "6  Shipped really fast.  I've had it about a mont...  Correct Size/Just Right   \n",
      "7   I don't love this, it's just a battery.  But ...               No Comment   \n",
      "8   It only last 1 year and i couldn't find where...               No Comment   \n",
      "9   The vendor immediately phoned me, listened ca...  Correct Size/Just Right   \n",
      "\n",
      "  PredictedLabel  Match  \n",
      "0     Wrong Size  False  \n",
      "1     Wrong Size  False  \n",
      "2     Wrong Size  False  \n",
      "3     Wrong Size  False  \n",
      "4     Wrong Size  False  \n",
      "5     Wrong Size  False  \n",
      "6     Wrong Size  False  \n",
      "7     Wrong Size  False  \n",
      "8     Wrong Size  False  \n",
      "9     Wrong Size  False  \n",
      "\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_10.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(10)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 10 reviews prompt v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 10 reviews saved to fit_predictions_first_10_promptv2.csv.\n",
      "Runtime: 8.01 seconds\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_10_promptv2.csv\"\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 10:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"nstruction: Classify the following review into one of the categories: \"Correct Size/Just Right,\" \"Wrong Size,\" or \"No Comment.\"\n",
    "Examples:\n",
    "1. \"Fits perfectly and works well with my setup.\" -> Correct Size/Just Right\n",
    "2. \"I had to modify it to make it fit my device.\" -> Wrong Size\n",
    "3. \"Shipped on time and is good quality.\" -> No Comment\n",
    "Review: {review}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 10 reviews saved to {output_file}.\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print runtime\n",
    "runtime = end_time - start_time\n",
    "print(f\"Runtime: {runtime:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted vs. Actual:\n",
      "                                          ReviewText                FINAL Fit  \\\n",
      "0  You will have to remove the window which is ve...               No Comment   \n",
      "1   It does what it is supposed to! Sure it does ...               No Comment   \n",
      "2  Item was delivered on time and was a direct re...               No Comment   \n",
      "3   This was a really great part, shipped fast, a...               No Comment   \n",
      "4  This puller worked getting off a stubborn wipe...               No Comment   \n",
      "5   Works ok, really just a quick adapter as the ...               No Comment   \n",
      "6  Shipped really fast.  I've had it about a mont...  Correct Size/Just Right   \n",
      "7   I don't love this, it's just a battery.  But ...               No Comment   \n",
      "8   It only last 1 year and i couldn't find where...               No Comment   \n",
      "9   The vendor immediately phoned me, listened ca...  Correct Size/Just Right   \n",
      "\n",
      "  PredictedLabel  Match  \n",
      "0     No Comment   True  \n",
      "1     No Comment   True  \n",
      "2     No Comment   True  \n",
      "3     No Comment   True  \n",
      "4     No Comment   True  \n",
      "5     No Comment   True  \n",
      "6     No Comment  False  \n",
      "7     No Comment   True  \n",
      "8     No Comment   True  \n",
      "9     No Comment  False  \n",
      "\n",
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_10_promptv2.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(10)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 50 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 50 reviews saved to fit_predictions_first_50.csv.\n",
      "Runtime: 35.33 seconds\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_50.csv\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 50:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"Instruction: Classify the following review into one of the categories: \"Correct Size/Just Right,\" \"Wrong Size,\" or \"No Comment.\"\n",
    "Examples:\n",
    "1. \"Fits perfectly and works well with my setup.\" -> Correct Size/Just Right\n",
    "2. \"I had to modify it to make it fit my device.\" -> Wrong Size\n",
    "3. \"Shipped on time and is good quality.\" -> No Comment\n",
    "Review: {review}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 50 reviews saved to {output_file}.\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print runtime\n",
    "runtime = end_time - start_time\n",
    "print(f\"Runtime: {runtime:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted vs. Actual:\n",
      "                                           ReviewText  \\\n",
      "0   You will have to remove the window which is ve...   \n",
      "1    It does what it is supposed to! Sure it does ...   \n",
      "2   Item was delivered on time and was a direct re...   \n",
      "3    This was a really great part, shipped fast, a...   \n",
      "4   This puller worked getting off a stubborn wipe...   \n",
      "5    Works ok, really just a quick adapter as the ...   \n",
      "6   Shipped really fast.  I've had it about a mont...   \n",
      "7    I don't love this, it's just a battery.  But ...   \n",
      "8    It only last 1 year and i couldn't find where...   \n",
      "9    The vendor immediately phoned me, listened ca...   \n",
      "10  Battery fired up on the first try and couldn't...   \n",
      "11  Everyone else was sold out... our kids love ri...   \n",
      "12   If quality matters to you, and you are lookin...   \n",
      "13   This battery does not have F2 terminals. They...   \n",
      "14  Looked far and wide for this battery as a repl...   \n",
      "15   Husband bought this for his motorcycle, and l...   \n",
      "16   I was a bit worried about ordering a battery ...   \n",
      "17  Quick shipping. So far the battery is living u...   \n",
      "18  Thanks for a great product. The batteries were...   \n",
      "19  I put this into a 1999 Mazda Miata MX-5.  It f...   \n",
      "20  This is an excellent product and works as adve...   \n",
      "21   I have not yet had the opportunity to use thi...   \n",
      "22   Product was delivered on time, and works well...   \n",
      "23  Worked like it was advertised and lots cheaper...   \n",
      "24  This seem to satify my needs and it was as che...   \n",
      "25   My low battery alarm started going off in the...   \n",
      "26  I was very pleased with the battery shipping w...   \n",
      "27  works as advertised except for the narrower te...   \n",
      "28  Battery only lasted 1 month after a cold spell...   \n",
      "29  Our CF Moto trike was purchased in 11/12   we ...   \n",
      "30   Even though we charged the battery for well o...   \n",
      "31   Nothing special about this one.  This item wa...   \n",
      "32  Its the battery i was looking to buy. It charg...   \n",
      "33   I liked the price and the previous reviews I ...   \n",
      "34   The acid delivery / installation system is we...   \n",
      "35  battery only lasted around 4-5 months then sud...   \n",
      "36  This battery was exactly what we needed. the c...   \n",
      "37   Installed battery right out of the shipping b...   \n",
      "38   Really good battery for the price, very usefu...   \n",
      "39  So far so good with this battery. We got this ...   \n",
      "40   Cheaper to order and install yourself instead...   \n",
      "41  The battery didn't hold a charge for more than...   \n",
      "42  Everything I wanted and more. This is a must h...   \n",
      "43   I ordered this item so I could do a little of...   \n",
      "44   I used this battery in my Fire Burglar Instru...   \n",
      "45  This is a good battery.  The company is respon...   \n",
      "46   This is a great company. Got two for my sonsE...   \n",
      "47  I have bought 2 of these batteries from this s...   \n",
      "48  I just installed it today in my FIOS system.  ...   \n",
      "49   The battery came verry quick, looked and fit ...   \n",
      "\n",
      "                  FINAL Fit PredictedLabel  Match  \n",
      "0                No Comment     No Comment   True  \n",
      "1                No Comment     No Comment   True  \n",
      "2                No Comment     No Comment   True  \n",
      "3                No Comment     No Comment   True  \n",
      "4                No Comment     No Comment   True  \n",
      "5                No Comment     No Comment   True  \n",
      "6   Correct Size/Just Right     No Comment  False  \n",
      "7                No Comment     No Comment   True  \n",
      "8                No Comment     No Comment   True  \n",
      "9   Correct Size/Just Right     No Comment  False  \n",
      "10               No Comment     No Comment   True  \n",
      "11               No Comment     No Comment   True  \n",
      "12               No Comment     No Comment   True  \n",
      "13  Correct Size/Just Right     No Comment  False  \n",
      "14  Correct Size/Just Right     No Comment  False  \n",
      "15               No Comment     No Comment   True  \n",
      "16               No Comment     No Comment   True  \n",
      "17               No Comment     No Comment   True  \n",
      "18               No Comment     No Comment   True  \n",
      "19  Correct Size/Just Right     No Comment  False  \n",
      "20               No Comment     No Comment   True  \n",
      "21               No Comment     No Comment   True  \n",
      "22  Correct Size/Just Right     No Comment  False  \n",
      "23               No Comment     No Comment   True  \n",
      "24               No Comment     No Comment   True  \n",
      "25               No Comment     No Comment   True  \n",
      "26               No Comment     No Comment   True  \n",
      "27  Correct Size/Just Right     No Comment  False  \n",
      "28               No Comment     No Comment   True  \n",
      "29               No Comment     No Comment   True  \n",
      "30               No Comment     No Comment   True  \n",
      "31  Correct Size/Just Right     No Comment  False  \n",
      "32               No Comment     No Comment   True  \n",
      "33               No Comment     No Comment   True  \n",
      "34  Correct Size/Just Right     No Comment  False  \n",
      "35               No Comment     No Comment   True  \n",
      "36               No Comment     No Comment   True  \n",
      "37               No Comment     No Comment   True  \n",
      "38               No Comment     No Comment   True  \n",
      "39               No Comment     No Comment   True  \n",
      "40  Correct Size/Just Right     No Comment  False  \n",
      "41               No Comment     No Comment   True  \n",
      "42               No Comment     No Comment   True  \n",
      "43               No Comment     No Comment   True  \n",
      "44               No Comment     No Comment   True  \n",
      "45               No Comment     No Comment   True  \n",
      "46               No Comment     No Comment   True  \n",
      "47               No Comment     No Comment   True  \n",
      "48               No Comment     No Comment   True  \n",
      "49  Correct Size/Just Right     No Comment  False  \n",
      "\n",
      "Accuracy: 78.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_50.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(50)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot first 500 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 50 reviews saved to fit_predictions_first_500.csv.\n",
      "Runtime: 359.05 seconds\n",
      "Comparison of Predicted vs. Actual:\n",
      "                                            ReviewText  \\\n",
      "0    You will have to remove the window which is ve...   \n",
      "1     It does what it is supposed to! Sure it does ...   \n",
      "2    Item was delivered on time and was a direct re...   \n",
      "3     This was a really great part, shipped fast, a...   \n",
      "4    This puller worked getting off a stubborn wipe...   \n",
      "..                                                 ...   \n",
      "495   If you have the rear defrost then this is not...   \n",
      "496   It's just a bit noisier than the factory Bosc...   \n",
      "497  This is the 3rd radiator my husband has ordere...   \n",
      "498   This was very easy to install and a necessary...   \n",
      "499   This liquid epoxy product repaired the crack ...   \n",
      "\n",
      "                   FINAL Fit PredictedLabel  Match  \n",
      "0                 No Comment     No Comment   True  \n",
      "1                 No Comment     No Comment   True  \n",
      "2                 No Comment     No Comment   True  \n",
      "3                 No Comment     No Comment   True  \n",
      "4                 No Comment     No Comment   True  \n",
      "..                       ...            ...    ...  \n",
      "495  Correct Size/Just Right     No Comment  False  \n",
      "496               No Comment     No Comment   True  \n",
      "497               No Comment     No Comment   True  \n",
      "498               No Comment     No Comment   True  \n",
      "499               No Comment     No Comment   True  \n",
      "\n",
      "[500 rows x 4 columns]\n",
      "\n",
      "Accuracy: 63.40%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_500.csv\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 500:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"Instruction: Classify the following review into one of the categories: \"Correct Size/Just Right,\" \"Wrong Size,\" or \"No Comment.\"\n",
    "Examples:\n",
    "1. \"Fits perfectly and works well with my setup.\" -> Correct Size/Just Right\n",
    "2. \"I had to modify it to make it fit my device.\" -> Wrong Size\n",
    "3. \"Shipped on time and is good quality.\" -> No Comment\n",
    "Review: {review}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=1024\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 50 reviews saved to {output_file}.\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print runtime\n",
    "runtime = end_time - start_time\n",
    "print(f\"Runtime: {runtime:.2f} seconds\")\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_500.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(500)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load tokenizer and quantized model\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_use_double_quant=True)\n",
    "\n",
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=16,  # Rank of the LoRA adapter\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "# Attach LoRA adapters to the model\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()  # Verify which parameters are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17497/1306022181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[\"text\"] = (\n",
      "/tmp/ipykernel_17497/1306022181.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[\"label\"] = subset[\"FINAL Fit\"]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f1fd7ca3f543908437f926c2dc8864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "data = pd.read_csv(\"fit.csv\")\n",
    "\n",
    "# Select a subset (e.g., 1,000 rows)\n",
    "subset = data.head(100)\n",
    "\n",
    "# Format the dataset for fine-tuning\n",
    "subset[\"text\"] = (\n",
    "    \"Instruction: Classify the following review into one of the categories: \"\n",
    "    '\"Correct Size/Just Right,\" \"Wrong Size,\" or \"No Comment.\" '\n",
    "    \"Review: \" + subset[\"ReviewText\"]\n",
    ")\n",
    "subset[\"label\"] = subset[\"FINAL Fit\"]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_pandas(subset[[\"text\", \"label\"]])\n",
    "\n",
    "# Tokenize the dataset\n",
    "def preprocess_data(batch):\n",
    "    inputs = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = tokenizer(batch[\"label\"], truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = hf_dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters:\n",
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 37\u001b[0m\n\u001b[1;32m     23\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     24\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Adjust based on your GPU memory\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Initialize Trainer\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     38\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                   \u001b[38;5;66;03m# Quantized model with LoRA adapters\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,            \u001b[38;5;66;03m# Training arguments\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset,  \u001b[38;5;66;03m# Tokenized dataset from Step 2\u001b[39;00m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting fine-tuning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/transformers/trainer.py:554\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# At this stage the model is already loaded\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_peft_model(model) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_model_quantized_and_qat_trainable:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for more details\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m     )\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantization_method_supports_training:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model you are trying to fine-tune is quantized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but that quantization method do not support training. Please open an issue on GitHub: https://github.com/huggingface/transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to request the support for training support for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from peft import PeftModel\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Define LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  # Task type for causal language modeling\n",
    "    inference_mode=False,          # Enable training mode\n",
    "    r=8,                           # LoRA rank\n",
    "    lora_alpha=16,                 # LoRA alpha\n",
    "    lora_dropout=0.1,              # LoRA dropout\n",
    ")\n",
    "\n",
    "# Attach LoRA adapters to the model\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Verify trainable parameters\n",
    "print(\"Trainable Parameters:\")\n",
    "model.print_trainable_parameters()  # Only LoRA layers should be trainable\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=2,  # Adjust based on your GPU memory\n",
    "    gradient_accumulation_steps=4,  # Accumulate gradients to simulate larger batch sizes\n",
    "    num_train_epochs=3,             # Define number of epochs\n",
    "    learning_rate=5e-5,             # Fine-tuning learning rate\n",
    "    fp16=True,                      # Enable mixed precision for efficiency\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                   # Quantized model with LoRA adapters\n",
    "    args=training_args,            # Training arguments\n",
    "    train_dataset=tokenized_dataset,  # Tokenized dataset from Step 2\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to fit_predictions_with_few_shot.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"fit.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define categories\n",
    "categories = [\"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\"]\n",
    "\n",
    "# Stratified sampling to pick 2 examples per category\n",
    "few_shot_examples = {}\n",
    "for category in categories:\n",
    "    category_examples = data[data[\"FINAL Fit\"] == category].sample(n=2, random_state=42)\n",
    "    few_shot_examples[category] = category_examples\n",
    "\n",
    "# Format examples for few-shot prompting\n",
    "few_shot_prompt = \"\"\n",
    "for category, examples in few_shot_examples.items():\n",
    "    for _, row in examples.iterrows():\n",
    "        review_text = row[\"ReviewText\"]\n",
    "        few_shot_prompt += f'Review: \"{review_text}\"\\nClassification -> {category}\\n\\n'\n",
    "\n",
    "# Format the final prompt structure\n",
    "def format_prompt(review, few_shot_prompt):\n",
    "    return f\"\"\"Instruction: Classify the following review into one of the categories: \"Correct Size/Just Right\", \"Wrong Size\", or \"No Comment\". Please respond only with the category name.\n",
    "Few-shot Examples:\n",
    "{few_shot_prompt}\n",
    "Input:\n",
    "Review: \"{review}\"\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "# Define output file\n",
    "output_file = \"fit_predictions_with_few_shot.csv\"\n",
    "\n",
    "# Prepare to write predictions\n",
    "with open(output_file, \"w\") as out_csv:\n",
    "    out_csv.write(\"ReviewText,PredictedLabel\\n\")  # Write headers\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        review_text = row[\"ReviewText\"]\n",
    "\n",
    "        # Generate the few-shot prompt\n",
    "        prompt = format_prompt(review_text, few_shot_prompt)\n",
    "\n",
    "        # Tokenize the input\n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "        ).to(\"cuda\")  # Ensure inputs are on GPU\n",
    "\n",
    "        # Generate prediction\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        # Decode the response\n",
    "        predicted_label = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Write result to file\n",
    "        out_csv.write(f'\"{review_text}\",\"{predicted_label}\"\\n')\n",
    "\n",
    "print(f\"Predictions saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
