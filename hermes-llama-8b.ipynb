{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: huggingface-cli: command not found\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Llama2 7b tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c952f72879643398979e60dcc6af340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Define the model name and cache directory\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"  # LLaMA 2-7B model\n",
    "cache_dir = \"/scratch/gilbreth/anand173/model_cache\"\n",
    "\n",
    "# Configure 4-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Use 4-bit quantization\n",
    "    bnb_4bit_use_double_quant=True,  # Enable double quantization for memory savings\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Use bfloat16 for computation\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# Load the model with 4-bit quantization and device map\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # Automatically allocate model layers across GPU/CPU\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "# Ensure the pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification response...\n",
      "Predicted Label: ### Instruction:\n",
      "Classify the following review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
      "\n",
      "### Input:\n",
      "Item was delivered on time and was a direct replcement\n",
      "\n",
      "### Response:\n",
      "Correct Size/Just Right\n",
      "\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "# Example review to classify\n",
    "review = \"Item was delivered on time and was a direct replcement\"\n",
    "\n",
    "# Format prompt for classification\n",
    "prompt = f\"\"\"### Instruction:\n",
    "Classify the following review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
    "\n",
    "### Input:\n",
    "{review}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    ").to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "# Generate the output\n",
    "print(\"Generating classification response...\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=10,           # Limit the response length\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode and display the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "print(f\"Predicted Label: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification response...\n",
      "Predicted Label: ### Instruction:\n",
      "Classify the following autoparts review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
      "\n",
      "\n",
      "### Examples:\n",
      "1. Review: \"order came quickly and is working fine and is much better price than going to Lowe's or Home Depot to purchase.\"\n",
      "   Classification -> No Comment\n",
      "2. Review: \"Perfect Fit - Ideal for when you don't need to replace an otherwise good OEM axle. Fits all FWD/AWD Volvo 850   S/V70 '93-'00\"\n",
      "   Classification -> Correct Size/Just Right\n",
      "3. Review: \"two different ends on cables. doesn't make sense. had to change the end on one side to fit it to the battery.\"\n",
      "   Classification -> Wrong Size\n",
      "\n",
      "\n",
      "### Input:\n",
      "Review: \"Have not had to use it yet - but I know how handy it is to have it available. Thanks\"\n",
      "### Response:\n",
      "No Comment\n",
      "\n",
      "### Input:\n",
      "Re\n"
     ]
    }
   ],
   "source": [
    "# Few-shot examples for the classification task\n",
    "few_shot_examples = \"\"\"\n",
    "### Examples:\n",
    "1. Review: \"order came quickly and is working fine and is much better price than going to Lowe's or Home Depot to purchase.\"\n",
    "   Classification -> No Comment\n",
    "2. Review: \"Perfect Fit - Ideal for when you don't need to replace an otherwise good OEM axle. Fits all FWD/AWD Volvo 850   S/V70 '93-'00\"\n",
    "   Classification -> Correct Size/Just Right\n",
    "3. Review: \"two different ends on cables. doesn't make sense. had to change the end on one side to fit it to the battery.\"\n",
    "   Classification -> Wrong Size\n",
    "\"\"\"\n",
    "\n",
    "# Example review to classify\n",
    "review = \"Have not had to use it yet - but I know how handy it is to have it available. Thanks\"\n",
    "\n",
    "# Format prompt with few-shot examples\n",
    "prompt = f\"\"\"### Instruction:\n",
    "Classify the following autoparts review into \"Correct Size/Just Right\", \"Wrong Size\", \"No Comment\". Please respond only with the category:\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "### Input:\n",
    "Review: \"{review}\"\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    ").to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "# Generate the output\n",
    "print(\"Generating classification response...\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=10,           # Limit the response length\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode and display the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "print(f\"Predicted Label: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 10 reviews prompt version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 10 reviews saved to fit_predictions_first_10.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_10.csv\"\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 10:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"### Instruction:\n",
    "Classify the following review into one of the categories: \"Correct Size/Just Right\", \"Wrong Size\", or \"No Comment\". Please respond only with the category name.\n",
    "\n",
    "### Categories:\n",
    "- \"Correct Size/Just Right\": The product fits as expected and performs its intended function without issues.\n",
    "- \"Wrong Size\": The product does not fit or requires modifications to work correctly.\n",
    "- \"No Comment\": The review does not mention size or fitting issues.\n",
    "\n",
    "### Examples:\n",
    "1. Review: \"order came quickly and is working fine and is much better price than going to Lowe's or Home Depot to purchase.\"\n",
    "   Classification -> No Comment\n",
    "2. Review: \"Perfect Fit - Ideal for when you don't need to replace an otherwise good OEM axle. Fits all FWD/AWD Volvo 850   S/V70 '93-'00\"\n",
    "   Classification -> Correct Size/Just Right\n",
    "3. Review: \"two different ends on cables. doesn't make sense. had to change the end on one side to fit it to the battery.\"\n",
    "   Classification -> Wrong Size\n",
    "\n",
    "### Input:\n",
    "Review: \"{review}\"\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 10 reviews saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted vs. Actual:\n",
      "                                          ReviewText                FINAL Fit  \\\n",
      "0  You will have to remove the window which is ve...               No Comment   \n",
      "1   It does what it is supposed to! Sure it does ...               No Comment   \n",
      "2  Item was delivered on time and was a direct re...               No Comment   \n",
      "3   This was a really great part, shipped fast, a...               No Comment   \n",
      "4  This puller worked getting off a stubborn wipe...               No Comment   \n",
      "5   Works ok, really just a quick adapter as the ...               No Comment   \n",
      "6  Shipped really fast.  I've had it about a mont...  Correct Size/Just Right   \n",
      "7   I don't love this, it's just a battery.  But ...               No Comment   \n",
      "8   It only last 1 year and i couldn't find where...               No Comment   \n",
      "9   The vendor immediately phoned me, listened ca...  Correct Size/Just Right   \n",
      "\n",
      "  PredictedLabel  Match  \n",
      "0     Wrong Size  False  \n",
      "1     Wrong Size  False  \n",
      "2     Wrong Size  False  \n",
      "3     Wrong Size  False  \n",
      "4     Wrong Size  False  \n",
      "5     Wrong Size  False  \n",
      "6     Wrong Size  False  \n",
      "7     Wrong Size  False  \n",
      "8     Wrong Size  False  \n",
      "9     Wrong Size  False  \n",
      "\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_10.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(10)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 10 reviews prompt v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 10 reviews saved to fit_predictions_first_10_promptv2.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_10_promptv2.csv\"\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 10:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"nstruction: Classify the following review into one of the categories: \"Correct Size/Just Right,\" \"Wrong Size,\" or \"No Comment.\"\n",
    "Examples:\n",
    "1. \"Fits perfectly and works well with my setup.\" -> Correct Size/Just Right\n",
    "2. \"I had to modify it to make it fit my device.\" -> Wrong Size\n",
    "3. \"Shipped on time and is good quality.\" -> No Comment\n",
    "Review: {review}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 10 reviews saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted vs. Actual:\n",
      "                                          ReviewText                FINAL Fit  \\\n",
      "0  You will have to remove the window which is ve...               No Comment   \n",
      "1   It does what it is supposed to! Sure it does ...               No Comment   \n",
      "2  Item was delivered on time and was a direct re...               No Comment   \n",
      "3   This was a really great part, shipped fast, a...               No Comment   \n",
      "4  This puller worked getting off a stubborn wipe...               No Comment   \n",
      "5   Works ok, really just a quick adapter as the ...               No Comment   \n",
      "6  Shipped really fast.  I've had it about a mont...  Correct Size/Just Right   \n",
      "7   I don't love this, it's just a battery.  But ...               No Comment   \n",
      "8   It only last 1 year and i couldn't find where...               No Comment   \n",
      "9   The vendor immediately phoned me, listened ca...  Correct Size/Just Right   \n",
      "\n",
      "  PredictedLabel  Match  \n",
      "0     No Comment   True  \n",
      "1     No Comment   True  \n",
      "2     No Comment   True  \n",
      "3     No Comment   True  \n",
      "4     No Comment   True  \n",
      "5     No Comment   True  \n",
      "6     No Comment  False  \n",
      "7     No Comment   True  \n",
      "8     No Comment   True  \n",
      "9     No Comment  False  \n",
      "\n",
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_10_promptv2.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(10)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 50 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 50 reviews saved to fit_predictions_first_50.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_50.csv\"\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 50:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"Instruction: Classify the following review into one of the categories: \"Correct Size/Just Right,\" \"Wrong Size,\" or \"No Comment.\"\n",
    "Examples:\n",
    "1. \"Fits perfectly and works well with my setup.\" -> Correct Size/Just Right\n",
    "2. \"I had to modify it to make it fit my device.\" -> Wrong Size\n",
    "3. \"Shipped on time and is good quality.\" -> No Comment\n",
    "Review: {review}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 50 reviews saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted vs. Actual:\n",
      "                                           ReviewText  \\\n",
      "0   You will have to remove the window which is ve...   \n",
      "1    It does what it is supposed to! Sure it does ...   \n",
      "2   Item was delivered on time and was a direct re...   \n",
      "3    This was a really great part, shipped fast, a...   \n",
      "4   This puller worked getting off a stubborn wipe...   \n",
      "5    Works ok, really just a quick adapter as the ...   \n",
      "6   Shipped really fast.  I've had it about a mont...   \n",
      "7    I don't love this, it's just a battery.  But ...   \n",
      "8    It only last 1 year and i couldn't find where...   \n",
      "9    The vendor immediately phoned me, listened ca...   \n",
      "10  Battery fired up on the first try and couldn't...   \n",
      "11  Everyone else was sold out... our kids love ri...   \n",
      "12   If quality matters to you, and you are lookin...   \n",
      "13   This battery does not have F2 terminals. They...   \n",
      "14  Looked far and wide for this battery as a repl...   \n",
      "15   Husband bought this for his motorcycle, and l...   \n",
      "16   I was a bit worried about ordering a battery ...   \n",
      "17  Quick shipping. So far the battery is living u...   \n",
      "18  Thanks for a great product. The batteries were...   \n",
      "19  I put this into a 1999 Mazda Miata MX-5.  It f...   \n",
      "20  This is an excellent product and works as adve...   \n",
      "21   I have not yet had the opportunity to use thi...   \n",
      "22   Product was delivered on time, and works well...   \n",
      "23  Worked like it was advertised and lots cheaper...   \n",
      "24  This seem to satify my needs and it was as che...   \n",
      "25   My low battery alarm started going off in the...   \n",
      "26  I was very pleased with the battery shipping w...   \n",
      "27  works as advertised except for the narrower te...   \n",
      "28  Battery only lasted 1 month after a cold spell...   \n",
      "29  Our CF Moto trike was purchased in 11/12   we ...   \n",
      "30   Even though we charged the battery for well o...   \n",
      "31   Nothing special about this one.  This item wa...   \n",
      "32  Its the battery i was looking to buy. It charg...   \n",
      "33   I liked the price and the previous reviews I ...   \n",
      "34   The acid delivery / installation system is we...   \n",
      "35  battery only lasted around 4-5 months then sud...   \n",
      "36  This battery was exactly what we needed. the c...   \n",
      "37   Installed battery right out of the shipping b...   \n",
      "38   Really good battery for the price, very usefu...   \n",
      "39  So far so good with this battery. We got this ...   \n",
      "40   Cheaper to order and install yourself instead...   \n",
      "41  The battery didn't hold a charge for more than...   \n",
      "42  Everything I wanted and more. This is a must h...   \n",
      "43   I ordered this item so I could do a little of...   \n",
      "44   I used this battery in my Fire Burglar Instru...   \n",
      "45  This is a good battery.  The company is respon...   \n",
      "46   This is a great company. Got two for my sonsE...   \n",
      "47  I have bought 2 of these batteries from this s...   \n",
      "48  I just installed it today in my FIOS system.  ...   \n",
      "49   The battery came verry quick, looked and fit ...   \n",
      "\n",
      "                  FINAL Fit PredictedLabel  Match  \n",
      "0                No Comment     No Comment   True  \n",
      "1                No Comment     No Comment   True  \n",
      "2                No Comment     No Comment   True  \n",
      "3                No Comment     No Comment   True  \n",
      "4                No Comment     No Comment   True  \n",
      "5                No Comment     No Comment   True  \n",
      "6   Correct Size/Just Right     No Comment  False  \n",
      "7                No Comment     No Comment   True  \n",
      "8                No Comment     No Comment   True  \n",
      "9   Correct Size/Just Right     No Comment  False  \n",
      "10               No Comment     No Comment   True  \n",
      "11               No Comment     No Comment   True  \n",
      "12               No Comment     No Comment   True  \n",
      "13  Correct Size/Just Right     No Comment  False  \n",
      "14  Correct Size/Just Right     No Comment  False  \n",
      "15               No Comment     No Comment   True  \n",
      "16               No Comment     No Comment   True  \n",
      "17               No Comment     No Comment   True  \n",
      "18               No Comment     No Comment   True  \n",
      "19  Correct Size/Just Right     No Comment  False  \n",
      "20               No Comment     No Comment   True  \n",
      "21               No Comment     No Comment   True  \n",
      "22  Correct Size/Just Right     No Comment  False  \n",
      "23               No Comment     No Comment   True  \n",
      "24               No Comment     No Comment   True  \n",
      "25               No Comment     No Comment   True  \n",
      "26               No Comment     No Comment   True  \n",
      "27  Correct Size/Just Right     No Comment  False  \n",
      "28               No Comment     No Comment   True  \n",
      "29               No Comment     No Comment   True  \n",
      "30               No Comment     No Comment   True  \n",
      "31  Correct Size/Just Right     No Comment  False  \n",
      "32               No Comment     No Comment   True  \n",
      "33               No Comment     No Comment   True  \n",
      "34  Correct Size/Just Right     No Comment  False  \n",
      "35               No Comment     No Comment   True  \n",
      "36               No Comment     No Comment   True  \n",
      "37               No Comment     No Comment   True  \n",
      "38               No Comment     No Comment   True  \n",
      "39               No Comment     No Comment   True  \n",
      "40  Correct Size/Just Right     No Comment  False  \n",
      "41               No Comment     No Comment   True  \n",
      "42               No Comment     No Comment   True  \n",
      "43               No Comment     No Comment   True  \n",
      "44               No Comment     No Comment   True  \n",
      "45               No Comment     No Comment   True  \n",
      "46               No Comment     No Comment   True  \n",
      "47               No Comment     No Comment   True  \n",
      "48               No Comment     No Comment   True  \n",
      "49  Correct Size/Just Right     No Comment  False  \n",
      "\n",
      "Accuracy: 78.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_50.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(50)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot first 500 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 50 reviews saved to fit_predictions_first_500.csv.\n",
      "Comparison of Predicted vs. Actual:\n",
      "                                            ReviewText  \\\n",
      "0    You will have to remove the window which is ve...   \n",
      "1     It does what it is supposed to! Sure it does ...   \n",
      "2    Item was delivered on time and was a direct re...   \n",
      "3     This was a really great part, shipped fast, a...   \n",
      "4    This puller worked getting off a stubborn wipe...   \n",
      "..                                                 ...   \n",
      "495   If you have the rear defrost then this is not...   \n",
      "496   It's just a bit noisier than the factory Bosc...   \n",
      "497  This is the 3rd radiator my husband has ordere...   \n",
      "498   This was very easy to install and a necessary...   \n",
      "499   This liquid epoxy product repaired the crack ...   \n",
      "\n",
      "                   FINAL Fit PredictedLabel  Match  \n",
      "0                 No Comment     No Comment   True  \n",
      "1                 No Comment     No Comment   True  \n",
      "2                 No Comment     No Comment   True  \n",
      "3                 No Comment     No Comment   True  \n",
      "4                 No Comment     No Comment   True  \n",
      "..                       ...            ...    ...  \n",
      "495  Correct Size/Just Right     No Comment  False  \n",
      "496               No Comment     No Comment   True  \n",
      "497               No Comment     No Comment   True  \n",
      "498               No Comment     No Comment   True  \n",
      "499               No Comment     No Comment   True  \n",
      "\n",
      "[500 rows x 4 columns]\n",
      "\n",
      "Accuracy: 63.40%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file path for the input reviews\n",
    "input_file = \"fit.csv\"\n",
    "output_file = \"fit_predictions_first_500.csv\"\n",
    "\n",
    "# Prepare to write results to a new CSV file\n",
    "with open(output_file, mode=\"w\", newline=\"\") as out_csv:\n",
    "    writer = csv.writer(out_csv)\n",
    "    writer.writerow([\"ReviewText\", \"PredictedLabel\"])  # Write headers\n",
    "\n",
    "    # Initialize a counter\n",
    "    review_count = 0\n",
    "\n",
    "    # Read and process each review from the input CSV file\n",
    "    with open(input_file, mode=\"r\") as in_csv:\n",
    "        reader = csv.DictReader(in_csv)\n",
    "        for row in reader:\n",
    "            if review_count >= 500:  # Process only the first 10 reviews\n",
    "                break\n",
    "\n",
    "            review = row[\"ReviewText\"]\n",
    "\n",
    "            # Format the prompt for each review\n",
    "            prompt = f\"\"\"Instruction: Classify the following review into one of the categories: \"Correct Size/Just Right,\" \"Wrong Size,\" or \"No Comment.\"\n",
    "Examples:\n",
    "1. \"Fits perfectly and works well with my setup.\" -> Correct Size/Just Right\n",
    "2. \"I had to modify it to make it fit my device.\" -> Wrong Size\n",
    "3. \"Shipped on time and is good quality.\" -> No Comment\n",
    "Review: {review}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=1024\n",
    "            ).to(\"cuda\")  # Send input tensors to GPU\n",
    "\n",
    "            # Generate the output\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,  # Limit the response length\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decode the response and clean it\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract only the classification label cleanly\n",
    "            if \"Classification ->\" in response:\n",
    "                response = response.split(\"Classification ->\")[-1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                # If no proper format, default to \"No Comment\" for robustness\n",
    "                response = \"No Comment\"\n",
    "\n",
    "            # Write the review and predicted label to the output CSV\n",
    "            writer.writerow([review, response])\n",
    "\n",
    "            # Increment the counter\n",
    "            review_count += 1\n",
    "\n",
    "print(f\"Predictions for the first 50 reviews saved to {output_file}.\")\n",
    "\n",
    "# File paths\n",
    "input_file = \"fit.csv\"  # Original file with actual labels\n",
    "predictions_file = \"fit_predictions_first_500.csv\"  # File with model predictions\n",
    "\n",
    "# Load input and prediction files as DataFrames\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure only the first 10 rows are used for comparison\n",
    "df_input = df_input.head(500)\n",
    "\n",
    "# Combine DataFrames for comparison\n",
    "# Use \"ReviewText\" as the matching key\n",
    "comparison_df = pd.merge(\n",
    "    df_input, \n",
    "    df_predictions, \n",
    "    on=\"ReviewText\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Compare the 'FINAL Fit' column with 'PredictedLabel'\n",
    "comparison_df[\"Match\"] = comparison_df[\"FINAL Fit\"] == comparison_df[\"PredictedLabel\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = comparison_df[\"Match\"].mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Comparison of Predicted vs. Actual:\")\n",
    "print(comparison_df[[\"ReviewText\", \"FINAL Fit\", \"PredictedLabel\", \"Match\"]])\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot examples:\n",
      "Review: ' This wiper was easy to install on my husband's '09 Chevy Colorado and it fit perfectly. Immediately my husband noticed that the curved shape of the wiper puts a strong, even pressure down on the windshield and does a noticeably better job of wiping then the previous wipers. I should also point out that these wipers are noise free. We're very pleased with the performance and highly recommend this high quality wiper. ' -> Classification: Correct Size/Just Right\n",
      "Review: 'I am very pleased with the way the progressive touring link makes my 06 street glide  handle in curves and around corners without the  wobble that I use to have. The ease of installation  and step by step instructions was really a plus.' -> Classification: Correct Size/Just Right\n",
      "Review: ' I used it in a 2006 Honda Accord 4 cylinder, and costs about half the price of an original Honda air filter. ' -> Classification: No Comment\n",
      "Review: ' I ordered these to keep in my vehicle, just in case I needed them. I had to use them once on someone else's vehicle, and they worked great!! The length is perfect! ' -> Classification: No Comment\n",
      "Review: ' Taking out the Stereo in this car is more complicated than others I have done, so I did not appreciate the fact that I have to put it all back together and wait for another Wiring Harness to arrive so I can take it apart and check to see if it fits. ' -> Classification: Wrong Size\n",
      "Review: ' Contrary to Amazon's, and several other online retailers, this part is not for a 1996 Nissan pickup.The connector is for the older style Nissan Hardbody pickups.I had to check NGK's website to find which O2 sensor was the right one for my vehicle. ' -> Classification: Wrong Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84439/156776494.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stratified_samples = df.groupby(\"FINAL Fit\", group_keys=False).apply(lambda x: x.sample(2, random_state=42))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3950caec2cb447f4ae4b26ae025667df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1772c4b827dc4245a98cf5ddce2a2be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff02e5e107c4571a8c82227b6a12f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabf1c45ddd8443a8005034b9fb02c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c440c3233ca4ec9be6e78b82b7ffe4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc82ed96d7e549f9857700d7cb76ff7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f99711019e4d429bef98a30696650d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cb57b4535247f98932ae7b60f8a324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your desired model\u001b[39;00m\n\u001b[1;32m     42\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Step 5: Predict labels for all reviews\u001b[39;00m\n\u001b[1;32m     46\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_predictions_with_stratified_shotting.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/transformers/modeling_utils.py:3990\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3987\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3989\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3990\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   3991\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3992\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3993\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   3994\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   3995\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   3996\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   3997\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   3998\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   3999\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   4000\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   4001\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   4002\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m   4003\u001b[0m     )\n\u001b[1;32m   4005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4006\u001b[0m     is_safetensors_available()\n\u001b[1;32m   4007\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   4008\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4009\u001b[0m ):\n\u001b[1;32m   4010\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/transformers/utils/hub.py:1098\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   1099\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1100\u001b[0m             shard_filename,\n\u001b[1;32m   1101\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1102\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1103\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1104\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   1105\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1106\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1107\u001b[0m             user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   1108\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1109\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   1110\u001b[0m             _commit_hash\u001b[38;5;241m=\u001b[39m_commit_hash,\n\u001b[1;32m   1111\u001b[0m         )\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    404\u001b[0m         path_or_repo_id,\n\u001b[1;32m    405\u001b[0m         filename,\n\u001b[1;32m    406\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    407\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    408\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    409\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    410\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    411\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    412\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    413\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    414\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    415\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/huggingface_hub/file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    844\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m    863\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    864\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    867\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    868\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    869\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m    871\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m    872\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m    873\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    874\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    875\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m    877\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    878\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    879\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/huggingface_hub/file_download.py:1011\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1009\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1011\u001b[0m     _download_to_tmp_and_move(\n\u001b[1;32m   1012\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mPath(blob_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.incomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1013\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mPath(blob_path),\n\u001b[1;32m   1014\u001b[0m         url_to_download\u001b[38;5;241m=\u001b[39murl_to_download,\n\u001b[1;32m   1015\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1016\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1017\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1018\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1019\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1022\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/huggingface_hub/file_download.py:1545\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1543\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1545\u001b[0m     http_get(\n\u001b[1;32m   1546\u001b[0m         url_to_download,\n\u001b[1;32m   1547\u001b[0m         f,\n\u001b[1;32m   1548\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1549\u001b[0m         resume_size\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m   1550\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1551\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1552\u001b[0m     )\n\u001b[1;32m   1554\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1555\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/huggingface_hub/file_download.py:454\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    452\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    456\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(amt\u001b[38;5;241m=\u001b[39mamt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/urllib3/response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_read(amt)\n\u001b[1;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/urllib3/response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt, read1\u001b[38;5;241m=\u001b[39mread1) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/site-packages/urllib3/response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/llama2/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Step 1: Load the input dataset\n",
    "df = pd.read_csv(\"fit.csv\")\n",
    "\n",
    "# Step 2: Stratified sampling - Get 2 samples per category\n",
    "stratified_samples = df.groupby(\"FINAL Fit\", group_keys=False).apply(lambda x: x.sample(2, random_state=42))\n",
    "\n",
    "# Prepare the examples for the prompt\n",
    "few_shot_examples = []\n",
    "for _, row in stratified_samples.iterrows():\n",
    "    example_text = f\"Review: '{row['ReviewText']}' -> Classification: {row['FINAL Fit']}\"\n",
    "    few_shot_examples.append(example_text)\n",
    "\n",
    "# Step 3: Build the prompt dynamically\n",
    "def build_prompt(review_text, few_shot_examples):\n",
    "    prompt = \"\"\"Instruction:\n",
    "Classify the following review into one of the categories: 'Correct Size/Just Right', 'Wrong Size', or 'No Comment'. Please respond only with the category name.\n",
    "\n",
    "Categories:\n",
    "- 'Correct Size/Just Right': Product fits as expected and works without issues.\n",
    "- 'Wrong Size': Product does not fit or required modifications.\n",
    "- 'No Comment': Review does not mention size or fitting issues.\n",
    "\n",
    "Examples:\\n\"\"\"\n",
    "    prompt += \"\\n\".join(few_shot_examples)\n",
    "    prompt += f\"\\n\\n### Input:\\nReview: '{review_text}'\\n### Response:\"\n",
    "    return prompt\n",
    "\n",
    "# Step 4: Predict labels without reloading model/tokenizer\n",
    "output_file = \"fit_predictions_with_stratified.csv\"\n",
    "results = []\n",
    "\n",
    "# Iterate over each review\n",
    "for _, row in df.iterrows():\n",
    "    review_text = row[\"ReviewText\"]\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = build_prompt(review_text, few_shot_examples)\n",
    "\n",
    "    # Tokenize input (model and tokenizer already loaded)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Extract only the predicted label\n",
    "    if \"Classification:\" in response:\n",
    "        predicted_label = response.split(\"Classification:\")[-1].strip()\n",
    "    else:\n",
    "        predicted_label = response  # Fallback\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"ReviewText\": review_text, \"PredictedLabel\": predicted_label})\n",
    "\n",
    "# Step 5: Save predictions to a CSV\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
